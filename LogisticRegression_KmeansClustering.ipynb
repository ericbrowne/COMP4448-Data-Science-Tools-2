{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Logistic Regression, Kmeans Clustering</center>\n",
    "<center> University of Denver </center>\n",
    "<center> Eric Browne </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the Data:\n",
    "# Start with the smaller dataset\n",
    "df = pd.read_csv('bank.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for data types and NaN Values\n",
    "print(df.dtypes)\n",
    "print(\"---\")\n",
    "print(df.isnull().sum())\n",
    "print('---')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values in the variables: (default, housing, contact, campaign, poutcome, previous)\n",
    "print(f\"Default: {df.default.unique()}\")\n",
    "print(f\"Housing: {df.housing.unique()}\")\n",
    "print(f\"Contact: {df.contact.unique()}\")\n",
    "print(f\"Campaign: {df.campaign.unique()}\")\n",
    "print(f\"poutcome: {df.poutcome.unique()}\")\n",
    "print(f\"previous: {df.previous.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)\n",
    "pd.options.display.width = 0   # automatically ajust to window length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all non-numeric into category data\n",
    "df['job'] = df['job'].astype('category')\n",
    "df['job'] = df['job'].cat.codes\n",
    "df['marital'] = df['marital'].astype('category')\n",
    "df['marital'] = df['marital'].cat.codes\n",
    "df['education'] = df['education'].astype('category')\n",
    "df['education'] = df['education'].cat.codes\n",
    "df['default'] = df['default'].astype('category')\n",
    "df['default'] = df['default'].cat.codes\n",
    "df['contact'] = df['contact'].astype('category')\n",
    "df['contact'] = df['contact'].cat.codes\n",
    "df['month'] = df['month'].astype('category')\n",
    "df['month'] = df['month'].cat.codes\n",
    "df['poutcome'] = df['poutcome'].astype('category')\n",
    "df['poutcome'] = df['poutcome'].cat.codes\n",
    "df['housing'] = df['housing'].astype('category')\n",
    "df['housing'] = df['housing'].cat.codes\n",
    "df['loan'] = df['loan'].astype('category')\n",
    "df['loan'] = df['loan'].cat.codes\n",
    "df['y'] = df['y'].astype('category')\n",
    "df['y'] = df['y'].cat.codes\n",
    "\n",
    "df = df.drop('pdays',axis=1)\n",
    "print(\"\\n\\nAfter converting to numeric, dropping pdays, and normalizing balance:\")\n",
    "print( df.head() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split original df into train and test\n",
    "features = df.drop('y',axis=1)\n",
    "label = df['y']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(features,label, test_size=0.3,random_state=420)\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the y variable for clustering\n",
    "df2 = df.drop('y',axis=1)\n",
    "df2.head() # or could also use 'features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numericCols = ['age','duration']\n",
    "scaler.fit(df2[numericCols])\n",
    "df2[numericCols] = scaler.transform(df2[numericCols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform PCA\n",
    "save_xtrain = Xtrain\n",
    "save_xtest = Xtest\n",
    "pca = PCA()\n",
    "df_pca_train = pca.fit_transform(save_xtrain)\n",
    "df_pca_test = pca.fit_transform(save_xtest)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"explained_variance = \")\n",
    "print(explained_variance)\n",
    "\n",
    "print(f'Params: {pca.get_params()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the amount of explained_variance:\n",
    "%matplotlib inline\n",
    "plt.plot(range(1,len(explained_variance)+1),explained_variance)\n",
    "plt.title('Explained Variance using PCA')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## But for visualization purposes, we'll break it down into 2 components\n",
    "pca = PCA(n_components=2)\n",
    "df_PCA = pca.fit_transform(df2)\n",
    "df_PCA # now a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Agglomerative clustering to get optimal number of clusters\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to plot the dendrogram\n",
    "    \"\"\"\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current += 1  # leaf node\n",
    "            else:\n",
    "                current += counts[child_idx - n_samples]\n",
    "        counts[i] = current\n",
    "\n",
    "    linkage = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    #dendrogram plot\n",
    "    dendrogram(linkage, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomodel = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "agglomodel.fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plot the top three levels of the dendrogram\n",
    "plot_dendrogram(agglomodel, truncate_mode='level', p=3)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=420)\n",
    "kmeans.fit(df_PCA)\n",
    "print('means for the 2 clusters are:')\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict with Kmeans\n",
    "clusterPreds = kmeans.predict(df_PCA)\n",
    "np.unique(clusterPreds) # to make sure that the predictions arent all the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_PCA.shape)\n",
    "print(clusterPreds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the clusters\n",
    "def plot_clustering(df_kmeans, kmeanLabels):\n",
    "    fig,ax = plt.subplots()\n",
    "\n",
    "    for i in range(len(df_kmeans)):\n",
    "        if kmeanLabels[i] == 0: theColor = 'red'\n",
    "        if kmeanLabels[i] == 1: theColor = 'green'\n",
    "        if kmeanLabels[i] == 2: theColor = 'blue'\n",
    "        if kmeanLabels[i] == 3: theColor = 'purple'\n",
    "        ax.scatter(df_kmeans[i][0],df_kmeans[i][1], s=9.5, alpha=1.0,color=theColor)\n",
    "        ax.set_title('kmeans')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "# Call the plotting function\n",
    "plot_clustering(df_PCA,clusterPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now use a for loop for plotting\n",
    "for i in range(2,5):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=420)\n",
    "    kmeans.fit(df_PCA)\n",
    "    clusterPreds = kmeans.predict(df_PCA)\n",
    "    plot_clustering(df_PCA,clusterPreds)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add values of the to the original dataset:\n",
    "kmeans = KMeans(n_clusters=2, random_state=420)\n",
    "kmeans.fit(df_PCA)\n",
    "## Predict with Kmeans\n",
    "clusterPreds = kmeans.predict(df_PCA)\n",
    "np.unique(clusterPreds) # to make sure that the predictions arent all the same\n",
    "df2['label'] = clusterPreds\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.set_params(max_iter=800)\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(df2.drop('label',axis=1),df2['label'],test_size=0.3,random_state=42)\n",
    "logit.fit(Xtrain,ytrain)\n",
    "logit_train_preds = logit.predict(Xtrain)\n",
    "print(f'Training F1 Score: {f1_score(logit_train_preds,ytrain)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [0.1,0.2,0.3,0.4,0.5,1.0]}\n",
    "grid_logit = GridSearchCV(logit, params, cv=3, scoring='accuracy',\n",
    "                           return_train_score=True)\n",
    "grid_logit.fit(features, label)\n",
    "best_params=grid_logit.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal cut off was 0.3\n",
    "final_logit = grid_logit.best_estimator_\n",
    "print(final_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Testing Accuracy: {accuracy_score(final_logit.predict(Xtest),ytest)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the data\n",
    "#predicting 'RainTomorrow'\n",
    "rainDF = pd.read_csv('RainOrNot.csv')\n",
    "rainDF.head()\n",
    "numericRain = ['MinTemp','MaxTemp','Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm','Humidity9am','Humidity3pm','Pressure9am','Pressure3pm','Cloud9am','Cloud3pm','Temp9am','Temp3pm']\n",
    "scale_rain = StandardScaler().fit(rainDF[numericRain])\n",
    "rainDF[numericRain] = scale_rain.transform(rainDF[numericRain])\n",
    "rainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(rainDF.drop('RainTomorrow',axis=1),rainDF['RainTomorrow'],test_size=0.3,random_state=420)\n",
    "\n",
    "## Make the Logit\n",
    "log_reg = sm.Logit(ytrain, Xtrain).fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the Summary\n",
    "print(log_reg.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test set predictions\n",
    "yhat = log_reg.predict(Xtest) \n",
    "prediction = list(map(round, yhat)) \n",
    "\n",
    "## Compute Accuracies:\n",
    "cm = confusion_matrix(ytest, prediction)  \n",
    "print (\"Confusion Matrix : \\n\", cm)  \n",
    "  \n",
    "# accuracy score of the model \n",
    "print('Test accuracy = ', accuracy_score(ytest, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using LogisticRegression() from sklearn, and Logitstic Regression from the statsmodels api achieved pretty good results form using cluster labels from our Kmeans algorithm to classify accurately**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
